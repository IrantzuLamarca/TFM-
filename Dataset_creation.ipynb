{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d0914b6-e4ec-4eb4-8309-c55d9f8a8cb6",
   "metadata": {},
   "source": [
    "# CODE FOR CREATING THE DATASET "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f269c7a7-50f0-4d90-a677-ecbeff08c27e",
   "metadata": {},
   "source": [
    "Once we have downloaded the mel spectrograms from the computer terminal, the next step is to create the dataset by extracting specific features from each of the downloaded mels and adding their corresponding tags. We now have 35 folders containing mel spectrograms, with around 200 in each. In total, we obtained 6,913 observations to be added to the dataset. \n",
    "\n",
    "I would like to mention that in this Python notebook, the only thing you (the reader) will need to change for the code to run are the file paths, such as \"C:/Users/PORTATIL/Desktop/mtg_data/melspecs_extraidos\". This path only works on my computer, but if you replace it with the folder where your data is stored, the code will work on yours as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1a9806-0609-4e82-b1b6-16a4a376b024",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8374de3-8060-4a9c-bbba-b9a7e2dd53d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a592b00-8626-4ed8-9c60-c0c9c280dd7c",
   "metadata": {},
   "source": [
    "## MEL SPECTOGRAM FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9000ac16-0c32-4614-aad4-28ad0cbb3bee",
   "metadata": {},
   "source": [
    "#### 00 FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943cd95-884b-4623-86f3-e2fd036ec081",
   "metadata": {},
   "source": [
    "The initial idea was to extract the following features: tempo, onsets per second, time signature, MFCCs, spectral centroid, spectral rolloff, key, root mean square (RMS), loudness, dynamic range, richness, and novelty. However, so far we have only downloaded the Mel spectrograms, and we can’t extract all the features we initially planned because some of them (tempo/BPM, time signature, onsets, average loudness, dynamic range, and key) require access to the original audio waveform for proper analysis, and we only have the .npy files. Since Mel spectrograms don’t retain information about phase, absolute amplitude, or fine temporal structure, those features can’t be derived from the data we currently have.\n",
    "\n",
    "Therefore, we’ve decided to replace those features with others that are compatible with the information available from the Mel spectrograms. The final list looks as follows:\n",
    "\n",
    "* **MFCCs** → Mel-frequency cepstral coefficients. Capture the general “timbre” of the sound.\n",
    "* **Spectral centroid** → Indicates whether the energy is concentrated in higher (brighter) or lower (darker) frequencies.\n",
    "* **Spectral rolloff** → The frequency below which a certain percentage of the total spectral energy is contained.\n",
    "* **Spectral richness (Frequency variance)** → The variability of energy across frequency bands, indicating timbral complexity.\n",
    "* **Energy per frame** → Total energy of each column in the spectrogram (i.e., intensity at each moment in time).\n",
    "* **Variance of energy** → How much the energy changes over time (variation in intensity).\n",
    "* **Spectral flux** → Measures how much the energy distribution changes from one frame to the next. Useful for detecting onsets and section changes.\n",
    "* **Temporal centroid** → The point in time where most of the energy is concentrated (e.g., beginning, middle, or end of the segment).\n",
    "* **RMS per frame** → Root mean square energy per frame. Roughly corresponds to perceived loudness at each moment.\n",
    "* **Spectral novelty** → Measures how much the Mel matrix changes from one frame to the next. Useful for detecting significant musical transitions.\n",
    "* **Attack/Decay slope** → The rate of change in energy at the start and end of a musical event, serving as an indicator of temporal dynamics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d86860-7251-4d9e-9f42-85773b16507a",
   "metadata": {},
   "source": [
    "We will start by analyzing a single folder, just to look at the information we have and to have an idea of what we want to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f571498-e930-4acc-b250-c1430824ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the folder from which to read the .npy files\n",
    "carpeta = \"C:/Users/PORTATIL/Desktop/mtg_data/melspecs_extraidos/00\"\n",
    "\n",
    "# Create a list for keeping the data\n",
    "datos = []\n",
    "archivos = [f for f in os.listdir(carpeta) if f.endswith(\".npy\")]\n",
    "\n",
    "# Read each .npy\n",
    "for archivo in tqdm(archivos, desc=f\"Procesando carpeta 00\"):\n",
    "    ruta = os.path.join(carpeta, archivo)\n",
    "    mel_array = np.load(ruta)           \n",
    "    datos.append([\"00\", archivo, mel_array]) \n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(datos, columns=[\"carpeta\", \"archivo\", \"mel_array\"])\n",
    "\n",
    "# See results\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f27a7d-c14e-4b4e-ab26-029324533d6c",
   "metadata": {},
   "source": [
    "We obtain a table that shows the source folder of each file, the file name, and the corresponding *mel\\_array*. The *mel\\_array* represents the spectrogram in the form of a 2D matrix, where rows correspond to frequency components and columns represent time frames.\n",
    "Now that we have seen how to analyze the data from a single folder, we will now extend the process to all folders and extract the previously mentioned features.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e39d6-075e-4d97-a647-e8b66de5da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract features from mel spectograms\n",
    "def obtener_features_mel(mel_array, sr=22050, hop_length=512):\n",
    "    \n",
    "    # Convert from dB to amplitude\n",
    "    mel_array = librosa.db_to_amplitude(mel_array)\n",
    "\n",
    "    # MFCCs\n",
    "    mfccs = librosa.feature.mfcc(S=librosa.power_to_db(mel_array), sr=sr)\n",
    "    mfcc_mean = np.mean(mfccs, axis=1)\n",
    "\n",
    "    # Centroid\n",
    "    centroid = librosa.feature.spectral_centroid(S=mel_array, sr=sr)\n",
    "    centroid_mean = np.mean(centroid)\n",
    "\n",
    "    # Rolloff \n",
    "    rolloff = librosa.feature.spectral_rolloff(S=mel_array, sr=sr)\n",
    "    rolloff_mean = np.mean(rolloff)\n",
    "\n",
    "    # Richness\n",
    "    richness = np.std(mel_array, axis=1).mean()\n",
    "\n",
    "    # Energy per frame\n",
    "    energy_per_frame = np.sum(mel_array, axis=0)\n",
    "    var_energy = np.var(energy_per_frame)\n",
    "\n",
    "    # Spectral flux and novelty\n",
    "    flux = np.sqrt(np.sum(np.diff(mel_array, axis=1)**2, axis=0))\n",
    "    flux_mean = np.mean(flux)\n",
    "    novelty = flux_mean\n",
    "\n",
    "    # Temporal centroid\n",
    "    times = librosa.frames_to_time(np.arange(mel_array.shape[1]), sr=sr, hop_length=hop_length)\n",
    "    temporal_centroid = np.sum(times * energy_per_frame) / np.sum(energy_per_frame)\n",
    "\n",
    "    # RMS and attack/decay slope\n",
    "    rms = np.sqrt(np.mean(np.square(mel_array), axis=0))\n",
    "    rms_mean = np.mean(rms)\n",
    "    attack_decay_slope = np.mean(np.abs(np.gradient(rms)))\n",
    "\n",
    "    # Build feature dictionary\n",
    "    features = {\n",
    "        **{f\"mfcc_{i}\": mfcc_mean[i] for i in range(len(mfcc_mean))},\n",
    "        \"centroid\": centroid_mean,\n",
    "        \"rolloff\": rolloff_mean,\n",
    "        \"richness\": richness,\n",
    "        \"var_energy\": var_energy,\n",
    "        \"spectral_flux\": flux_mean,\n",
    "        \"temporal_centroid\": temporal_centroid,\n",
    "        \"rms\": rms_mean,\n",
    "        \"novelty\": novelty,\n",
    "        \"attack_decay_slope\": attack_decay_slope,\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "# Process all .npy files in a folder, extracts features, and saves them to a CSV file\n",
    "def procesar_carpeta(carpeta_dir, carpeta_salida, sr=22050, hop_length=512):\n",
    "    \n",
    "    datos = []\n",
    "    carpeta_nombre = os.path.basename(carpeta_dir)\n",
    "    archivos = [f for f in os.listdir(carpeta_dir) if f.endswith('.npy')]\n",
    "\n",
    "    for archivo in tqdm(archivos, desc=f\"Procesando carpeta: {carpeta_nombre}\"):\n",
    "        ruta = os.path.join(carpeta_dir, archivo)\n",
    "        try:\n",
    "            mel_array = np.load(ruta)\n",
    "            features = obtener_features_mel(mel_array, sr=sr, hop_length=hop_length)\n",
    "            track_id = os.path.splitext(archivo)[0]\n",
    "\n",
    "            features[\"track_id\"] = track_id\n",
    "            features[\"carpeta\"] = carpeta_nombre\n",
    "            datos.append(features)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Error processing {archivo}: {e}\")\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(datos)\n",
    "\n",
    "    # Reorder columns (track\\_id and folder first)\n",
    "    columnas_ordenadas = ['track_id', 'carpeta'] + [col for col in df.columns if col not in ['track_id', 'carpeta']]\n",
    "    df = df[columnas_ordenadas]\n",
    "    df.set_index(\"track_id\", inplace=True)\n",
    "\n",
    "    # Save CSV\n",
    "    os.makedirs(carpeta_salida, exist_ok=True)\n",
    "    ruta_salida = os.path.join(carpeta_salida, f\"features_clean_{carpeta_nombre}.csv\")\n",
    "    df.to_csv(ruta_salida)\n",
    "    print(f\"File saved in: {ruta_salida}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Use of the script\n",
    "if __name__ == \"__main__\":\n",
    "    carpeta_mel = \"C:/Users/PORTATIL/Desktop/mtg_data/melspecs_extraidos/00\"\n",
    "    carpeta_salida = \"C:/Users/PORTATIL/Desktop/mtg_data/data_limpia\"\n",
    "\n",
    "    df_features = procesar_carpeta(carpeta_mel, carpeta_salida)\n",
    "    print(df_features.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c89d4-a726-4ef9-8324-eede88c40bd7",
   "metadata": {},
   "source": [
    "We will conduct an analysis of the first 2 files:\n",
    "\n",
    "**1009600.npy** → This file presents a distribution of MFCCs where MFCC\\_0 is quite low (-181.78), suggesting that this track may have a relatively lower overall energy compared to others. The spectral centroid (2439.58 Hz) indicates that the energy is distributed in the mid-frequency range, while the spectral richness (0.3257) and energy variance (173.66) point to a moderate variety of frequency components which is not particularly high. Both the spectral flux (1.33) and novelty (1.33) are moderate, which may imply that this piece does not exhibit abrupt spectral changes, especially when compared to more intense tracks. The RMS value (0.48) reflects a rather restrained average intensity.\n",
    "\n",
    "**1012000.npy** → This file shows a less extreme MFCC\\_0 value (-120.22), which suggests a higher overall energy level than the first file. The spectral centroid (1514.70 Hz) is lower, indicating that the track leans toward a less bright sound, with more energy concentrated in the low and mid frequencies. The energy variance (108.48) and spectral richness (0.214) are somewhat lower than in the previous example, implying less variability and a simpler spectral texture. However, the spectral flux and novelty values (3.13) are higher, which could suggest that this piece exhibits more dynamic spectral changes and a more pronounced temporal evolution.\n",
    "\n",
    "In summary,  from our function we obtain the following:\n",
    "\n",
    "* **mfcc\\_0–mfcc\\_19**: Capture the general timbre of the sound.\n",
    "* **Centroid, rolloff, richness**: Describe the distribution of energy across frequencies.\n",
    "* **var\\_energy, spectral\\_flux, temporal\\_centroid**: Capture the temporal evolution of energy.\n",
    "* **rms, novelty, attack\\_decay\\_slope**: Reflect aspects of intensity and dynamic behavior.\n",
    "\n",
    "Let’s clarify why MFCCs range from 0 to 19. MFCC stands for *Mel-Frequency Cepstral Coefficients*. These coefficients are used to represent the general shape of the audio spectrum on a scale that aligns with human hearing. When computing MFCCs, the output is a matrix where **MFCC\\_0** captures the overall energy of the spectrum (general intensity level), while **MFCC\\_1 to MFCC\\_19** represent increasingly fine details of the spectral distribution; such as brightness or darkness, frequency profile, and timbral texture. The use of 20 coefficients (from 0 to 19) is standard in audio analysis, as this number is typically sufficient to represent most musical timbres. \n",
    "\n",
    "With these features in place, the goal is to apply the same extraction process to the remaining folders using a for loop (for avoiding overloading the computer and preventing memory errors) and then merge everything into a single dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7a17dd-e490-468b-aab4-ef2e430ad6af",
   "metadata": {},
   "source": [
    "#### ALL FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b6299-8fc9-4363-8766-1b2619aab588",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function for obtaining features \n",
    "def obtener_features_mel(mel_array, sr=22050, hop_length=512):\n",
    "    mel_array = librosa.db_to_amplitude(mel_array)\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(S=librosa.power_to_db(mel_array), sr=sr)\n",
    "    mfcc_mean = np.mean(mfccs, axis=1)\n",
    "\n",
    "    centroid = librosa.feature.spectral_centroid(S=mel_array, sr=sr).flatten()\n",
    "    rolloff = librosa.feature.spectral_rolloff(S=mel_array, sr=sr).flatten()\n",
    "    flux = np.sqrt(np.sum(np.diff(mel_array, axis=1)**2, axis=0))\n",
    "    rms = np.sqrt(np.mean(mel_array**2, axis=0))\n",
    "    energy_per_frame = np.sum(mel_array, axis=0)\n",
    "\n",
    "    features = {\n",
    "        **{f\"mfcc_{i}\": mfcc_mean[i] for i in range(len(mfcc_mean))},\n",
    "        \"centroid\": np.mean(centroid),\n",
    "        \"rolloff\": np.mean(rolloff),\n",
    "        \"richness\": np.std(mel_array, axis=1).mean(),\n",
    "        \"var_energy\": np.var(energy_per_frame),\n",
    "        \"spectral_flux\": np.mean(flux),\n",
    "        \"temporal_centroid\": np.sum(librosa.frames_to_time(np.arange(mel_array.shape[1]), sr=sr, hop_length=hop_length) * energy_per_frame) / np.sum(energy_per_frame),\n",
    "        \"rms\": np.mean(rms),\n",
    "        \"novelty\": np.mean(flux),\n",
    "        \"attack_decay_slope\": np.mean(np.abs(np.gradient(rms))),\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "# Function for processing a folder\n",
    "def procesar_carpeta(carpeta_dir, nombre_carpeta, output_dir):\n",
    "    archivos = [f for f in os.listdir(carpeta_dir) if f.endswith('.npy')]\n",
    "    datos = []\n",
    "\n",
    "    for archivo in tqdm(archivos, desc=f\" Processing folder {nombre_carpeta}\"):\n",
    "        ruta = os.path.join(carpeta_dir, archivo)\n",
    "        try:\n",
    "            mel_array = np.load(ruta)\n",
    "            features = obtener_features_mel(mel_array)\n",
    "            track_id = os.path.splitext(archivo)[0]\n",
    "            fila = {\"track_id\": track_id, \"carpeta\": nombre_carpeta, **features}\n",
    "            datos.append(fila)\n",
    "        except Exception as e:\n",
    "            print(f\" Error in file {archivo}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(datos)\n",
    "    df = df[[\"track_id\", \"carpeta\"] + [col for col in df.columns if col not in [\"track_id\", \"carpeta\"]]]\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    ruta_salida = os.path.join(output_dir, f\"features_clean_{nombre_carpeta}.csv\")\n",
    "    df.to_csv(ruta_salida, index=False)\n",
    "    print(f\" Saved: {ruta_salida}\")\n",
    "    return df\n",
    "\n",
    "# Process in chunks of 5 folders\n",
    "carpeta_base = \"C:/Users/PORTATIL/Desktop/mtg_data/melspecs_extraidos\"\n",
    "output_dir = \"C:/Users/PORTATIL/Desktop/mtg_data/features_limpios\"\n",
    "\n",
    "carpetas = [f\"{i:02d}\" for i in range(36)]  # 00 a 35\n",
    "chunk_size = 5\n",
    "\n",
    "for i in range(0, len(carpetas), chunk_size):\n",
    "    bloque = carpetas[i:i+chunk_size]\n",
    "    print(f\"\\n Processing folder chunk: {bloque}\")\n",
    "\n",
    "    for carpeta in bloque:\n",
    "        carpeta_dir = os.path.join(carpeta_base, carpeta)\n",
    "        if os.path.isdir(carpeta_dir):\n",
    "            procesar_carpeta(carpeta_dir, carpeta, output_dir)\n",
    "        else:\n",
    "            print(f\" Folder {carpeta_dir} not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f8e68-ca54-4a56-936c-5f0ba33f5ebb",
   "metadata": {},
   "source": [
    "Let’s check the head of the DataFrame from the first 5 folders to see if everything was processed as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758389ac-fbe4-49c1-a8d2-178237c9f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path for obtaining cleaned CSV files\n",
    "ruta_limpios = \"C:/Users/PORTATIL/Desktop/mtg_data/features_limpios\"\n",
    "\n",
    "# Ordered list of the first 5 CSV files\n",
    "csv_files = sorted([f for f in os.listdir(ruta_limpios) if f.endswith(\".csv\")])[:5]\n",
    "\n",
    "# Show head of each file\n",
    "for archivo in csv_files:\n",
    "    ruta = os.path.join(ruta_limpios, archivo)\n",
    "    print(f\"\\n Showing head of: {archivo}\")\n",
    "    df = pd.read_csv(ruta)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ca86b4-58cd-4a9f-b198-dd4ace6ad302",
   "metadata": {},
   "source": [
    "#### SAVING FULL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf566b-146f-4ffc-9f44-2f62f17ac881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of cleaned CSV files\n",
    "ruta_limpios = \"C:/Users/PORTATIL/Desktop/mtg_data/features_limpios\"\n",
    "\n",
    "# List of all generated CSV files\n",
    "csv_files = sorted([f for f in os.listdir(ruta_limpios) if f.endswith(\".csv\")])\n",
    "\n",
    "# Read and merge all the files\n",
    "df_final = pd.concat(\n",
    "    [pd.read_csv(os.path.join(ruta_limpios, archivo)) for archivo in csv_files],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Summary of final dataframe\n",
    "print(\"Final dataset created with shape:\", df_final.shape)\n",
    "print(df_final.head())\n",
    "\n",
    "# Save as CSV\n",
    "ruta_salida_csv = \"C:/Users/PORTATIL/Desktop/mtg_data/features_final.csv\"\n",
    "df_final.to_csv(ruta_salida_csv, index=False)\n",
    "print(f\" Saved in: {ruta_salida_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f714c7d6-d6da-42eb-8fd6-fb860dfe995c",
   "metadata": {},
   "source": [
    "We now have the dataset with the extracted features. The next step is to merge it with the mood/theme metadata by adding a new column that indicates the mood/theme associated with each track. We'll perform the merge using the track_id as the common key between both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f562edc-2bc9-4138-b911-38ab5172b4ae",
   "metadata": {},
   "source": [
    "## MOOD/THEME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ae0f69-bd03-43f0-b701-4e238f63e423",
   "metadata": {},
   "source": [
    "It is necessary to examine the structure of the mood/theme file in order to understand its format and determine the most appropriate way to process and integrate it with the feature dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f209bd4-8775-4050-95e3-34942f0a3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the mood/theme file\n",
    "ruta_mood = \"C:/Users/PORTATIL/Desktop/Carpetas R/TFM/mtg-jamendo-dataset-master/mtg-jamendo-dataset-master/data/autotagging_moodtheme.tsv\"\n",
    "\n",
    "# Show structure\n",
    "with open(ruta_mood, encoding='utf-8') as f:\n",
    "    for _ in range(10):\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf3c23-e5e8-4fb3-a9db-5bb65849ff36",
   "metadata": {},
   "source": [
    "As observed, the document contains a **track_id** column and a **tags** column (along with others). The track_id column will be used to merge this information with our dataset. In the following code block, the tags column is handled in a special way because each track can have multiple mood/theme tags separated by tab characters within the same line of the file. Instead of splitting each tag into separate columns from the start (which could break the DataFrame structure if the number of tags varies), all tags are grouped into a single column as a list of strings. This step is essential for preserving the complete and flexible information, as it later allows us to safely split these lists of tags into individual columns (tag1, tag2, etc.) in a structured manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481150b3-ebbb-4a04-a0b6-b893ebfebf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_mood = \"C:/Users/PORTATIL/Desktop/Carpetas R/TFM/mtg-jamendo-dataset-master/mtg-jamendo-dataset-master/data/autotagging_moodtheme.tsv\"\n",
    "\n",
    "# Lists to store data\n",
    "rows = []\n",
    "\n",
    "with open(ruta_mood, encoding='utf-8') as f:\n",
    "    header = f.readline().strip().split('\\t')\n",
    "    \n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        base_fields = parts[:5]\n",
    "        tags = parts[5:]\n",
    "        rows.append(base_fields + [tags])\n",
    "\n",
    "# Create dataframe with column names\n",
    "columnas = header[:5] + ['TAGS']\n",
    "df_mood = pd.DataFrame(rows, columns=columnas)\n",
    "\n",
    "# Extract numeric track_id \n",
    "df_mood['track_id'] = df_mood['TRACK_ID'].str.extract(r'(\\d+)$').astype(int)\n",
    "\n",
    "print(df_mood.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5634ee20-02d7-4fa0-85d1-1785749d314e",
   "metadata": {},
   "source": [
    "We can now see that the tags column is a list of strings, and that we have generated a new track_id containing only the numeric identifier. Now, we are ready to separate the tags column into different tags. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f54882-5615-455d-81f4-643f30367953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand list of tags into separate columns\n",
    "df_tags_expandido = df_mood['TAGS'].apply(pd.Series)\n",
    "df_tags_expandido.columns = [f'tag{i+1}' for i in range(df_tags_expandido.shape[1])]\n",
    "\n",
    "# Concatenate the expanded tags as new columns to the original dataframe\n",
    "df_mood_expandido = pd.concat([df_mood.drop(columns=['TAGS']), df_tags_expandido], axis=1)\n",
    "\n",
    "print(df_mood_expandido)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4898fba0-dccc-40b8-b831-6ce5fb84ccc1",
   "metadata": {},
   "source": [
    "The tracks with multiple tags now have those tags separated into individual columns. Let’s proceed to merge this with our final dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b0b78-e6c1-44bb-9cfa-3b2c7f24fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['track_id'] = df_features['track_id'].astype(int)\n",
    "df_mood_expandido['track_id'] = df_mood_expandido['track_id'].astype(int)\n",
    "\n",
    "# Merge\n",
    "df_completo = pd.merge(df_features, df_mood_expandido, on='track_id', how='left')\n",
    "\n",
    "print(df_completo.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f442d-722e-48b8-8043-882c4815a5f5",
   "metadata": {},
   "source": [
    "We can see that all columns have been merged, not just the tags and track_id. We'll remove the unnecessary ones. Additionally, we want the tags to display only the label names, removing the prefix **mood/theme---**.\n",
    "\n",
    "First, let's check the names of all columns in the current dataset to decide which ones to drop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a931d-e18b-4647-a125-fc0e74907e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_completo.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f67934c-49fe-468e-8df8-671c357f88a8",
   "metadata": {},
   "source": [
    "These are the columns we need to remove: \"TRACK_ID\", \"ARTIST_ID\", \"ALBUM_ID\", \"PATH\", \"DURATION\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97b782-af2e-4590-a306-a7c9e8a7bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns\n",
    "columnas_a_eliminar = ['TRACK_ID', 'ARTIST_ID', 'ALBUM_ID', 'PATH', 'DURATION']\n",
    "df_completo = df_completo.drop(columns=[col for col in columnas_a_eliminar if col in df_completo.columns])\n",
    "\n",
    "print(df_completo.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1007f5-dc20-4213-938d-29f33c011506",
   "metadata": {},
   "source": [
    "Last thing is to remove the prefix mood/theme---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa6405-80b5-4d26-bcb4-b6e0d17ca53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify tag columns \n",
    "columnas_tag = [col for col in df_completo.columns if col.startswith('tag')]\n",
    "\n",
    "# Replace 'mood/theme---' \n",
    "for col in columnas_tag:\n",
    "    df_completo[col] = df_completo[col].map(\n",
    "        lambda x: x.replace('mood/theme---', '') if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    "# Results\n",
    "print(df_completo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b620efda-4acb-471c-bef1-1d03ec649d2b",
   "metadata": {},
   "source": [
    "We will save the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674de18-97b7-41d6-bcad-5f9d30c41c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_salida = \"C:/Users/PORTATIL/Desktop/mtg_data/features_final_mood_theme.csv\"\n",
    "df_completo.to_csv(ruta_salida, index=False)\n",
    "\n",
    "print(\"Saved in:\", ruta_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68098b99-f80f-4461-8bc2-d6b00f033bf4",
   "metadata": {},
   "source": [
    "## ADDING MP3s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78442f-8c8d-4bc9-86b1-75a8d8969d34",
   "metadata": {},
   "source": [
    "We analyzed the features extracted from the mel spectrograms, but they are not sufficient for the scale of the task we want to perform. Therefore, we decided to download the MP3 audio files in order to extract additional features from them. We will begin processing them and attempting to merge this information with the existing table containing the Mel spectrograms.\n",
    "\n",
    "As a first step, we will simply try to read the MP3 files and create a table that contains the name of each file along with the folder it comes from.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d3d91-f6fb-45d3-945c-9756bae7c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the downloaded MP3 files are located\n",
    "base_path = r\"E:\\TFM\\mp3_low\"\n",
    "\n",
    "# List for saving data\n",
    "data = []\n",
    "\n",
    "# Analyze all the folders and files\n",
    "for root, _, files in os.walk(base_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mp3\"):\n",
    "            full_path = os.path.join(root, file)\n",
    "            folder_name = os.path.basename(root)\n",
    "            data.append({\n",
    "                \"archivo\": file,\n",
    "                \"carpeta_origen\": folder_name\n",
    "            })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    " \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add8dae6-3d1f-4ce5-a437-45fd017a8b4f",
   "metadata": {},
   "source": [
    "We obtained what we wanted. We are now going to remove the **.low\\.mp3** suffix from each file name so that we can later merge it with our other table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450179af-d7ef-4b29-a81e-f2d2ac9390ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"archivo\"] = df[\"archivo\"].str.replace(\".low.mp3\", \"\", regex=False)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a9d50-7f8b-4de0-a9db-22e38d7075b4",
   "metadata": {},
   "source": [
    "We will also select only the tracks that have both a Mel spectrogram and an MP3 file, so we can work more efficiently and comfortably with the MP3 data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d432ca-e217-4876-bbc8-5d681f13864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv\n",
    "csv_path = r\"C:\\Users\\PORTATIL\\Desktop\\mtg_data\\features_final_mood_theme.csv\"\n",
    "df_ids = pd.read_csv(csv_path)\n",
    "\n",
    "# Make sure that type of data is string\n",
    "df_ids[\"track_id\"] = df_ids[\"track_id\"].astype(str)\n",
    "\n",
    "# Convert \"archivo\" column into string \n",
    "df[\"archivo\"] = df[\"archivo\"].astype(str)\n",
    "\n",
    "# Filter tracks with both mel and mp3\n",
    "df_filtrado = df[df[\"archivo\"].isin(df_ids[\"track_id\"])]\n",
    "\n",
    "# See number of coincidences\n",
    "print(f\"Coincidences: {len(df_filtrado)}\")\n",
    "\n",
    "print(df_filtrado.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1889b46f-1758-426f-b3f1-e83a20597aed",
   "metadata": {},
   "source": [
    "We can see that there are approximately 7,000 files. From those we have retained we are going to extract a set of features in order to later merge them with our existing table and build a more complete dataset.\n",
    "\n",
    "The features to be extracted from the MP3 audio files are:\n",
    "- Tempo / BPM → The overall speed of the song, measured in beats per minute. Calculated using beat detection from the audio waveform.\n",
    "- Onsets per second → Frequency of distinct sonic events (e.g., drum hits or note attacks) per second.\n",
    "- RMS → Root Mean Square energy; indicates the average intensity of the track.\n",
    "- RMS Dynamic Range → Difference between the loudest and softest moments in the track, reflecting its dynamic expressiveness.\n",
    "- Loudness → Estimated average volume in decibels; reflects how loud the track sounds overall.\n",
    "- Temporal Centroid → The approximate moment in the track where most of the energy is concentrated.\n",
    "- Key Estimate → The estimated musical key (0 = C, 1 = C♯, ..., 11 = B); represents the tonal center of the piece.\n",
    "\n",
    "We  will proceed in a way that avoids overloading the system when processing all 7,000 audio files. We will divide the data into chunks of 500 files and process each block separately. After processing all blocks, we will combine the results into a final dataset.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ca6260-e847-4565-a9b5-f2e609d15a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 7000 files\n",
    "df = pd.read_csv(\"mp3_filtrados.csv\")\n",
    "\n",
    "# Base path where the files are organized by folders\n",
    "base_path = r\"E:\\TFM\\mp3_low\"\n",
    "\n",
    "# List for saving results\n",
    "all_features = []\n",
    "\n",
    "# Chunk size\n",
    "chunk_size = 500\n",
    "num_chunks = (len(df) // chunk_size) + 1\n",
    "\n",
    "print(f\"Processing {len(df)} files in {num_chunks} chunks...\")\n",
    "\n",
    "# Process by chunk\n",
    "for chunk_idx in range(num_chunks):\n",
    "    print(f\"Processing chunk {chunk_idx + 1}/{num_chunks}...\")\n",
    "    chunk = df.iloc[chunk_idx * chunk_size : (chunk_idx + 1) * chunk_size]\n",
    "\n",
    "    for _, row in tqdm(chunk.iterrows(), total=len(chunk), leave=False):\n",
    "        track_id = str(row[\"archivo\"])\n",
    "        folder = str(row[\"carpeta_origen\"]).zfill(2)\n",
    "        file_path = os.path.join(base_path, folder, f\"{track_id}.low.mp3\")\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            y, sr = librosa.load(file_path, sr=None, duration=30)\n",
    "\n",
    "            # Tempo\n",
    "            tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "\n",
    "            # Onsets per second\n",
    "            onsets = librosa.onset.onset_detect(y=y, sr=sr)\n",
    "            duration = librosa.get_duration(y=y, sr=sr)\n",
    "            onsets_per_sec = len(onsets) / duration if duration > 0 else 0\n",
    "\n",
    "            # RMS and dynamic range\n",
    "            rms = librosa.feature.rms(y=y)[0]\n",
    "            rms_mean = np.mean(rms)\n",
    "            rms_dynamic_range = np.max(rms) - np.min(rms)\n",
    "\n",
    "            # Loudness\n",
    "            loudness = librosa.amplitude_to_db(np.abs(y), ref=np.max)\n",
    "            loudness_mean = np.mean(loudness)\n",
    "\n",
    "            # Temporal centroid\n",
    "            times = np.arange(len(rms))\n",
    "            temporal_centroid = np.sum(times * rms) / np.sum(rms) if np.sum(rms) > 0 else 0\n",
    "\n",
    "            # Key\n",
    "            chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "            key_estimate = np.argmax(np.mean(chroma, axis=1))\n",
    "\n",
    "            # Append to the main list\n",
    "            all_features.append({\n",
    "                \"track_id\": track_id,\n",
    "                \"tempo_bpm\": tempo,\n",
    "                \"onsets_per_sec\": onsets_per_sec,\n",
    "                \"rms_mean\": rms_mean,\n",
    "                \"rms_dynamic_range\": rms_dynamic_range,\n",
    "                \"loudness_mean_db\": loudness_mean,\n",
    "                \"temporal_centroid\": temporal_centroid,\n",
    "                \"key_estimate\": key_estimate\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {track_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Save results\n",
    "features_df = pd.DataFrame(all_features)\n",
    "features_df.to_csv(\"mp3_features.csv\", index=False)\n",
    "print(\"Extraction completed. Saved as 'mp3_features.csv'\")\n",
    "\n",
    "features_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84f3a1-d468-4ae5-b835-9230ed494bf6",
   "metadata": {},
   "source": [
    "We now have the dataset ready. Let’s proceed to merge the two tables: the one containing features from the MP3 files and the one with features from the Mel spectrograms.\n",
    "\n",
    "As mentioned in the beginning, we will use the track_id as the common key to align the rows correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09202022-a580-4d6f-becb-d9a71ba70c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Mel spectrogram table\n",
    "mel_df = pd.read_csv(r\"C:\\Users\\PORTATIL\\Desktop\\mtg_data\\features_final_mood_theme.csv\")\n",
    "\n",
    "# Load mp3 table\n",
    "audio_df = pd.read_csv(\"mp3_features.csv\")\n",
    "\n",
    "# Ensure that IDs are strings\n",
    "mel_df[\"track_id\"] = mel_df[\"track_id\"].astype(str)\n",
    "audio_df[\"track_id\"] = audio_df[\"track_id\"].astype(str)\n",
    "\n",
    "# Merge tables (by track_id)\n",
    "merged_df = mel_df.merge(audio_df, on=\"track_id\", how=\"inner\")\n",
    "\n",
    "# Drop 'carpeta\\_origen' if it was mistakenly included from another table\n",
    "if \"carpeta_origen\" in merged_df.columns:\n",
    "    merged_df = merged_df.drop(columns=[\"carpeta_origen\"])\n",
    "\n",
    "# Save dataset\n",
    "merged_df.to_csv(\"tabla_completa_unificada.csv\", index=False)\n",
    "print(\"Final table saved as 'tabla_completa_unificada.csv'\")\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca122a5-84fe-4ea3-a155-921c0691253c",
   "metadata": {},
   "source": [
    "## INSTRUMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c4d8cc-18fc-45bd-9992-71c8a4f2fbc1",
   "metadata": {},
   "source": [
    "To enhance our exploratory data analysis (or just to have another view of it in case of being necessary), we will also include metadata about the instruments present in each track and the genre to which each song is classified.\n",
    "\n",
    "We will start with the instruments. Let's begin by examining the structure of the document to understand how the information is organized and how we can process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b547b4c-1f74-4a82-8ec6-5a802eb6bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"C:/Users/PORTATIL/Desktop/Carpetas R/TFM/mtg-jamendo-dataset-master/mtg-jamendo-dataset-master/data/autotagging_instrument.tsv\", encoding='utf-8') as f:\n",
    "    for i in range(30): \n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9874cd-a8ec-4727-a096-70752e401f76",
   "metadata": {},
   "source": [
    "As we can see, the document has the same structure as the mood/theme file, except that this time the tags refer to instruments. Therefore, we will follow the same process to incorporate them into our dataset. \n",
    "\n",
    "We will not provide as many explanations as for the mood tags, since it is understood that they have already been given previously and everything is clear, as we are simply copying the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a1a436-1c7f-4f41-b3db-a5b819b51a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_inst = \"C:/Users/PORTATIL/Desktop/Carpetas R/TFM/mtg-jamendo-dataset-master/mtg-jamendo-dataset-master/data/autotagging_instrument.tsv\"\n",
    "\n",
    "# Lists to store data\n",
    "rows = []\n",
    "\n",
    "with open(ruta_inst, encoding='utf-8') as f:\n",
    "    header = f.readline().strip().split('\\t')\n",
    "    \n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        base_fields = parts[:5]\n",
    "        tags = parts[5:]\n",
    "        rows.append(base_fields + [tags])\n",
    "\n",
    "# Create dataframe with column names\n",
    "columnas = header[:5] + ['TAGS']\n",
    "df_inst = pd.DataFrame(rows, columns=columnas)\n",
    "\n",
    "# Extract numeric track_id \n",
    "df_inst['track_id'] = df_inst['TRACK_ID'].str.extract(r'(\\d+)$').astype(int)\n",
    "\n",
    "print(df_inst.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ac56b-1c56-4ebd-acfd-55d98a5d10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand list of tags into separate columns\n",
    "df_inst_expandido = df_inst['TAGS'].apply(pd.Series)\n",
    "df_inst_expandido.columns = [f'inst{i+1}' for i in range(df_inst_expandido.shape[1])]\n",
    "\n",
    "# Merge with original dataframe\n",
    "df_inst_expandido = pd.concat([df_inst.drop(columns=['TAGS']), df_inst_expandido], axis=1)\n",
    "\n",
    "print(df_inst_expandido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f154e-7ac0-483a-a98f-c1795361f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv(r\"C:\\Users\\PORTATIL\\Desktop\\mtg_data\\tabla_completa_unificada.csv\")\n",
    "\n",
    "merged_df['track_id'] = merged_df['track_id'].astype(int)\n",
    "df_inst_expandido['track_id'] = df_inst_expandido['track_id'].astype(int)\n",
    "\n",
    "# Merge\n",
    "df_mood_inst = pd.merge(merged_df, df_inst_expandido, on='track_id', how='left')\n",
    "\n",
    "print(df_mood_inst.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c024ca-3010-471c-84b9-14f52925418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names\n",
    "print(df_mood_inst.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b33e97f-3b43-48bc-9f7d-b459952fa99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "columnas_quitar = ['TRACK_ID', 'ARTIST_ID', 'ALBUM_ID', 'PATH', 'DURATION']\n",
    "df_mood_inst = df_mood_inst.drop(columns=[col for col in columnas_quitar if col in df_mood_inst.columns])\n",
    "\n",
    "print(df_mood_inst.head(5))\n",
    "\n",
    "df_mood_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75095e1-afd8-4342-9660-6027c2ca0ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new changes\n",
    "print(df_mood_inst.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870635b4-8404-4496-8bf2-a5aef23b579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify tag columns \n",
    "columnas_inst = [col for col in df_mood_inst.columns if col.startswith('inst')]\n",
    "\n",
    "# Replace 'instrument---' \n",
    "for col in columnas_inst:\n",
    "    df_mood_inst[col] = df_mood_inst[col].map(\n",
    "        lambda x: x.replace('instrument---', '') if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    "# Results\n",
    "print(df_mood_inst.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467b5f6-6502-49b2-9b8a-87fb69c02c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all columns without truncating\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Show first 5 rows of full DataFrame\n",
    "print(df_mood_inst.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1054cab-282a-4828-a5f3-02cfda1201a9",
   "metadata": {},
   "source": [
    "Perfect, what we did here is the same as with mood/theme, and it turned out just as we wanted. Now we not only have the features and mood/theme columns, but we have also added the instrument columns in the same format. Next, we are going to follow the exact same process to add the genre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f8055-a197-4c99-b0f4-f146af59f8eb",
   "metadata": {},
   "source": [
    "## GENRE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eeeb77-3e9f-4bee-8248-d4060eeb5e26",
   "metadata": {},
   "source": [
    "Let's begin by examining the structure of the document to understand how the information is organized and how we can process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53acfec0-bf62-4380-aedd-37404d6662a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/PORTATIL/Desktop/Carpetas R/TFM/mtg-jamendo-dataset-master/mtg-jamendo-dataset-master/data/autotagging_genre.tsv\", encoding='utf-8') as f:\n",
    "    for i in range(30):  # muestra primeras 30 líneas\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380e93e8-f8c7-4439-acf6-250567e4c242",
   "metadata": {},
   "source": [
    "We can see that the structure is exactly the same as before. Since the process is exactly the same as the one we followed in the mood/theme and instruments sections, we will not provide further explanations beyond commenting on the code in the chunks, so that it does not become tedious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176d9d1-b9d7-44f4-bd10-b12bfabe052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_genre = \"C:/Users/PORTATIL/Desktop/Carpetas R/TFM/mtg-jamendo-dataset-master/mtg-jamendo-dataset-master/data/autotagging_genre.tsv\"\n",
    "\n",
    "# Lists to store data\n",
    "rows = []\n",
    "\n",
    "with open(ruta_genre, encoding='utf-8') as f:\n",
    "    header = f.readline().strip().split('\\t')\n",
    "    \n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        base_fields = parts[:5]\n",
    "        tags = parts[5:]\n",
    "        rows.append(base_fields + [tags])\n",
    "\n",
    "# Create dataframe with column names\n",
    "columnas = header[:5] + ['TAGS']\n",
    "df_genre = pd.DataFrame(rows, columns=columnas)\n",
    "\n",
    "# Extract numeric track_id \n",
    "df_genre['track_id'] = df_genre['TRACK_ID'].str.extract(r'(\\d+)$').astype(int)\n",
    "\n",
    "print(df_genre.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a0a40-7b19-48c4-90b1-362cb46f2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand list of tags into separate columns\n",
    "df_genre_expandido = df_genre['TAGS'].apply(pd.Series)\n",
    "df_genre_expandido.columns = [f'genre{i+1}' for i in range(df_genre_expandido.shape[1])]\n",
    "\n",
    "# Merge with original dataframe\n",
    "df_genre_expandido = pd.concat([df_genre.drop(columns=['TAGS']), df_genre_expandido], axis=1)\n",
    "\n",
    "print(df_genre_expandido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f6dd4-5967-43e3-8e3f-78b925ec3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mood_inst['track_id'] = df_mood_inst['track_id'].astype(int)\n",
    "df_genre_expandido['track_id'] = df_genre_expandido['track_id'].astype(int)\n",
    "\n",
    "# Merge\n",
    "df_mood_inst_genre = pd.merge(df_mood_inst, df_genre_expandido, on='track_id', how='left')\n",
    "\n",
    "print(df_mood_inst_genre.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ceff5-90e5-4813-8f1b-235a23ceb07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names\n",
    "print(df_mood_inst_genre.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3999da56-03cc-4560-9aa1-d5bedb05d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns\n",
    "columnas_borrar = ['TRACK_ID', 'ARTIST_ID', 'ALBUM_ID', 'PATH', 'DURATION']\n",
    "df_mood_inst_genre = df_mood_inst_genre.drop(columns=[col for col in columnas_borrar if col in df_mood_inst_genre.columns])\n",
    "\n",
    "print(df_mood_inst_genre.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9689c4f1-3216-416b-ab7f-b58ac0a2c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify tag columns \n",
    "columnas_genre = [col for col in df_mood_inst_genre.columns if col.startswith('genre')]\n",
    "\n",
    "# Replace 'genre---' \n",
    "for col in columnas_genre:\n",
    "    df_mood_inst_genre[col] = df_mood_inst_genre[col].map(\n",
    "        lambda x: x.replace('genre---', '') if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    "# Results\n",
    "print(df_mood_inst_genre.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47f64c-3081-435d-b637-da79b5381425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to dataset\n",
    "ruta_salida = \"C:/Users/PORTATIL/Desktop/mtg_data/df_mood_inst_genre.csv\"\n",
    "df_mood_inst_genre.to_csv(ruta_salida, index=False)\n",
    "\n",
    "print(\"Saved in:\", ruta_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbca0f2-b134-430e-92d1-0ef0e0fb6652",
   "metadata": {},
   "source": [
    "We now have the complete table with all the features and the tags for mood/theme, instruments, and genre. We can start analyzing the data and preparing it for the EDA in R."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae009ff-325f-4d29-8d35-75f645adc319",
   "metadata": {},
   "source": [
    "## ADD DURATION FOR EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f063560-402f-4139-9f7a-dc5305e75cfb",
   "metadata": {},
   "source": [
    "As we analyzed the data, we realized that we need to normalize some variables, and for that we require the duration of each track; therefore, we are going to extract it and add it to the dataset.\n",
    "\n",
    "In the previous steps, we saw that the mood/theme, instruments, and genre documents included the duration of each track (which we removed without realizing we would need it). Therefore, we are going to use the same mood/theme document to add the duration back into the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0d4bc-02b6-4b95-9fc8-719b989528ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load current dataset (without duration)\n",
    "df_actual = pd.read_csv(r\"C:\\Users\\PORTATIL\\Desktop\\mtg_data\\df_mood_inst_genre.csv\")\n",
    "\n",
    "# Load .tsv file that contains duration\n",
    "\n",
    "ruta_mood = \"C:/Users/PORTATIL/Desktop/Carpetas R/TFM/mtg-jamendo-dataset-master/mtg-jamendo-dataset-master/data/autotagging_moodtheme.tsv\"\n",
    "\n",
    "# Lists to store data\n",
    "rows = []\n",
    "\n",
    "with open(ruta_mood, encoding='utf-8') as f:\n",
    "    header = f.readline().strip().split('\\t')\n",
    "    \n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        base_fields = parts[:5]\n",
    "        tags = parts[5:]\n",
    "        rows.append(base_fields + [tags])\n",
    "\n",
    "# Create dataframe with column names\n",
    "columnas = header[:5] + ['TAGS']\n",
    "df_mood = pd.DataFrame(rows, columns=columnas)\n",
    "\n",
    "# Extract numeric track_id \n",
    "df_mood['track_id'] = df_mood['TRACK_ID'].str.extract(r'(\\d+)$').astype(int)\n",
    "\n",
    "print(df_mood.head())\n",
    "\n",
    "# Check columns to see which one to use as a key\n",
    "print(\"Columnas en df_actual:\", df_actual.columns)\n",
    "print(\"Columnas en df_mood:\", df_mood.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229efbb7-a1ae-474a-afab-80075a6f5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with only track_id and DURATION\n",
    "df_duracion = df_mood[['track_id', 'DURATION']].copy()\n",
    "\n",
    "# Ensure that both track_id are of the same type\n",
    "df_actual['track_id'] = df_actual['track_id'].astype(int)\n",
    "df_duracion['track_id'] = df_duracion['track_id'].astype(int)\n",
    "\n",
    "# Merge\n",
    "df_final = pd.merge(df_actual, df_duracion, on='track_id', how='left')\n",
    "\n",
    "# Save results\n",
    "df_final.to_csv(r\"C:\\Users\\PORTATIL\\Desktop\\mtg_data\\df_con_duration.csv\", index=False)\n",
    "\n",
    "print(\"Final file saved with the 'DURATION' column added\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf45b2-6bc7-4b53-b41f-610d17635de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed971e-1d45-4317-873c-3d4b15ddd152",
   "metadata": {},
   "source": [
    "Finally, we have the complete dataset with all the previous columns (features + mood, instruments and genre tags) along with duration, which will allow us to scale our variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
